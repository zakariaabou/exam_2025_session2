{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Problème - Session n°2 : une variable cachée"
      ],
      "metadata": {
        "id": "GYE9s4-HA1o_"
      },
      "id": "GYE9s4-HA1o_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans ce problème, on travaille sur un jeu de données comportant 50.000 entrées $x_i$ et des cibles $y_i$. Les entrées sont des vecteurs de taille 10 (au format torch), les cibles sont des scalaires construits à partir de cinq fonctions différentes ($f_0$, ..., $f_4$) : \\\n",
        "\n",
        "$$ \\forall i, \\exists k\\in [0,4] \\:\\: \\text{tel que} \\: f_k(x_i) = y_i $$\n",
        "\n",
        "Ces fonctions sont inconnues, ainsi que l'indice $k$. Par contre, on sait que le groupe des 1000 premières cibles ont été construites à partir du même indice  $k$, de même pour les mille  suivantes, et ainsi de suite.\n",
        "\n",
        "Le but est de parvenir à rassembler les groupes de cibles qui ont été générées avec le même indice $k$ (avec la même fonction)."
      ],
      "metadata": {
        "id": "pknhArHLLPP-"
      },
      "id": "pknhArHLLPP-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Example d'échantillonnage du dataset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "! git clone https://github.com/XXXXXXX/exam_2025_session2.git\n",
        "! cp exam_2025_session2/utils/utils.py .\n",
        " from utils import Problem1Dataset\n",
        "\n",
        "dataset = Problem1Dataset()\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "for batch in dataloader:\n",
        "    x_batch, y_batch, k_batch, idx_batch = batch\n",
        "    print(\"Batch input shape:\", x_batch.shape)\n",
        "    print(\"Batch target shape:\", y_batch.shape)\n",
        "    print(\"Batch k shape:\", k_batch.shape) # indice k (pas utilisable à l'entraînement)\n",
        "    print(\"Batch indices shape:\", idx_batch.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "zqFIZKgTPK14"
      },
      "id": "zqFIZKgTPK14",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Consignes :**\n",
        "- Entraîner l'architecture proposée dans la cellule suivante.\n",
        "- Montrer que les vecteurs 2D de self.theta permettent de répondre\n",
        "  au problème posé.\n",
        "- Décrire le rôle de self.theta, du vector noise \\\n",
        " et ainsi que la raison de la division par 1000 (**indices // 1000** dans le code)."
      ],
      "metadata": {
        "id": "-q1zuebPPvob"
      },
      "id": "-q1zuebPPvob"
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepMLP(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim=256):\n",
        "        super(DeepMLP, self).__init__()\n",
        "        self.theta = nn.Parameter(torch.randn(50, 2))\n",
        "        self.fc1 = nn.Linear(input_dim + 2, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, indices):\n",
        "        theta_batch = self.theta[indices // 1000, :]\n",
        "        noise = torch.normal(mean=torch.zeros_like(theta_batch),\n",
        "                             std=torch.ones_like(theta_batch))\n",
        "        x = torch.cat([x, theta_batch + noise], dim=1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x, theta_batch"
      ],
      "metadata": {
        "id": "idbO80HfPdiQ"
      },
      "id": "idbO80HfPdiQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2000\n",
        "batch_size = ... # A régler\n",
        "loss_fn = ... # Standard pour cee type de tâche"
      ],
      "metadata": {
        "id": "UVmpuK5mnXY5"
      },
      "id": "UVmpuK5mnXY5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}